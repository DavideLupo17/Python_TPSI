{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYCdTVZiR4WXwSYX1F3wlD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavideLupo17/Python_TPSI/blob/main/machinelearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Learning**"
      ],
      "metadata": {
        "id": "5ZOZPtoIZiao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9CpBiR-ZhpD",
        "outputId": "0f6397da-6fbf-4dbd-804c-664c586c98a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "import joblib\n",
        "\n",
        "# Creazione del modello\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compilazione del modello\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Carica il dataset MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalizza e ridimensiona le immagini\n",
        "x_train = x_train.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Codifica one-hot per le etichette\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Addestra il modello\n",
        "model.fit(x_train, y_train, epochs=25, batch_size=64, validation_split=0.10)\n",
        "\n",
        "# Montaggio di Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Salvataggio del modello su Google Drive\n",
        "model_path = '/content/drive/MyDrive/model.joblib'\n",
        "joblib.dump(model, model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hInljpKksTkU",
        "outputId": "21b04a62-fbf9-400e-d428-445e51a1fb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "844/844 [==============================] - 50s 57ms/step - loss: 0.2035 - accuracy: 0.9382 - val_loss: 0.0751 - val_accuracy: 0.9755\n",
            "Epoch 2/5\n",
            "844/844 [==============================] - 49s 58ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
            "Epoch 3/5\n",
            "844/844 [==============================] - 49s 59ms/step - loss: 0.0385 - accuracy: 0.9875 - val_loss: 0.0373 - val_accuracy: 0.9898\n",
            "Epoch 4/5\n",
            "844/844 [==============================] - 51s 61ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0403 - val_accuracy: 0.9888\n",
            "Epoch 5/5\n",
            "844/844 [==============================] - 48s 57ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0440 - val_accuracy: 0.9895\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Monta Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Percorso del modello su Google Drive\n",
        "model_path = '/content/drive/MyDrive/model.joblib'\n",
        "\n",
        "# Carica il modello\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Ora puoi utilizzare il modello per fare previsioni, ad esempio:\n",
        "# prediction = model.predict(input_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjvdGbCPtaJS",
        "outputId": "346b0e4d-9049-47c8-f85f-d2b7e1b37412"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvataggio del modello\n",
        "drive.mount('/content/drive')\n",
        "model_path = '/content/drive/MyDrive/mnist_model.h5'\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9wrVlJFzNXO",
        "outputId": "f41b4944-f63d-4a5c-b68f-4139745ee589"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "\n",
        "# Carica l'immagine dal tuo dispositivo\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "img = Image.open(io.BytesIO(uploaded[image_path]))\n",
        "\n",
        "# Preprocessa l'immagine\n",
        "img = img.convert('L')  # Converti l'immagine a scala di grigi se non lo è già\n",
        "img = img.resize((28, 28))\n",
        "img_array = np.array(img)\n",
        "img_array = img_array.reshape((1, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Fai previsioni sull'immagine\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Interpreta le previsioni\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Stampa la classe predetta\n",
        "print(f\"Classe predetta: {predicted_class}\")\n",
        "\n",
        "\n",
        "# Chiedi all'utente di correggere manualmente la classe\n",
        "corrected_class = int(input('Enter corrected class: '))\n",
        "\n",
        "# Correggi l'etichetta nei dati di test\n",
        "corrected_label = np.zeros_like(y_test[0])\n",
        "corrected_label[corrected_class] = 1\n",
        "y_test[0] = corrected_label\n",
        "\n",
        "# riaddestra set\n",
        "model.fit(x_test, y_test, epochs=1, batch_size=64)\n",
        "\n",
        "# Fai previsioni sull'immagine corretta\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "\n",
        "# Salvataggio del modello\n",
        "drive.mount('/content/drive')\n",
        "model_path = '/content/drive/MyDrive/mnist_model.h5'\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "NP8NcGGwz6Qt",
        "outputId": "ca924df5-a832-422c-e15b-ead78bc774b3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9e0cd7c7-c3b9-4b0d-9629-ab778ffb7474\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9e0cd7c7-c3b9-4b0d-9629-ab778ffb7474\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 5D9DFF35-1729-4DAA-A653-79907774ADB9.jpeg to 5D9DFF35-1729-4DAA-A653-79907774ADB9.jpeg\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Classe predetta: 4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-f199014fb020>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Chiedi all'utente di correggere manualmente la classe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mcorrected_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter corrected class: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Correggi l'etichetta nei dati di test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Numero massimo di iterazioni manuali\n",
        "max_iterations = 3\n",
        "\n",
        "for iteration in range(max_iterations):\n",
        "    # Prendi un sottoinsieme di immagini dal set di test\n",
        "    sample_indices = np.random.choice(len(x_test), size=2, replace=False)\n",
        "    sample_images = x_test[sample_indices]\n",
        "\n",
        "    # Fai previsioni sulle immagini di esempio\n",
        "    predicted_classes = np.random.randint(0, 10, size=len(sample_images))\n",
        "\n",
        "    # Mostra le immagini e le previsioni\n",
        "    fig, axs = plt.subplots(1, len(sample_images))\n",
        "    for i, (img, pred) in enumerate(zip(sample_images, predicted_classes)):\n",
        "        axs[i].imshow(img, cmap='gray')\n",
        "        axs[i].set_title(f\"Pre: {pred}\")\n",
        "        axs[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Etichettatura manuale simulata\n",
        "    corrected_classes = np.array([int(input(f\"Enter corrected class for image {i + 1}: \")) for i in range(len(sample_images))])\n",
        "    corrected_labels = to_categorical(corrected_classes, num_classes=10)\n",
        "    y_test[sample_indices] = corrected_labels\n",
        "    print(y_test[sample_indices])\n",
        "\n",
        "\n",
        "# Stampa il set di etichette corrette\n",
        "print(\"\\nCorrected labels:\\n\")\n",
        "print(y_test)\n",
        "\n",
        "# Salvataggio del modello\n",
        "drive.mount('/content/drive')\n",
        "model_path = '/content/drive/MyDrive/mnist_model.h5'\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t9m39sqE5ERU",
        "outputId": "162da9a3-bff2-4c01-c1d9-e548c7b16947"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter corrected class for image 1: 4\n",
            "Enter corrected class for image 2: 9\n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter corrected class for image 1: 9\n",
            "Enter corrected class for image 2: 6\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter corrected class for image 1: 0\n",
            "Enter corrected class for image 2: 8\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "\n",
            "Corrected labels:\n",
            "\n",
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}